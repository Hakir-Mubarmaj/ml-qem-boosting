{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9479f265",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "End-to-end demo (toy data)\n",
    "\n",
    "This notebook demonstrates the full pipeline on toy data:\n",
    "\n",
    "Generate toy raw JSONL dataset\n",
    "\n",
    "Prepare parquet feature snapshots (incremental feature families)\n",
    "\n",
    "Run a small feature sweep (RF + XGB, very small trials)\n",
    "\n",
    "Run a group-ensemble experiment on the largest feature set\n",
    "\n",
    "Run analysis and display the error vs #features figure\n",
    "\n",
    "Note: this notebook is designed to run locally. Ensure your working directory is the repo root (where src/ is located) and that dependencies from requirements.txt are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: generate toy JSONL using the helper script\n",
    "from src.data.make_dataset import generate_toy_jsonl\n",
    "out_jsonl = 'data/raw/toy_demo.jsonl'\n",
    "generate_toy_jsonl(out_jsonl, n_samples=300, seed=0)\n",
    "print('Wrote toy dataset to', out_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eee40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: prepare parquet features for incremental family sets\n",
    "from src.experiments.prepare_parquet import prepare_parquets\n",
    "manifest = prepare_parquets('data/raw/toy_demo.jsonl', out_dir='data/features_demo', pca_components=2)\n",
    "print('Manifest:', manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09025c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: run a small sweep with RF and XGB (no tuning) -- this calls the trainer\n",
    "import subprocess\n",
    "subprocess.run([\n",
    "'python', 'src/experiments/run_feature_sweep.py',\n",
    "'--out', 'results/demo_sweep',\n",
    "'--models', 'rf', 'xgb',\n",
    "'--pca', '2'\n",
    "])\n",
    "\n",
    "\n",
    "# After completion, results are in results/demo_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: pick the largest features parquet produced earlier and run group ensemble\n",
    "import os\n",
    "import json\n",
    "with open('data/features_demo/manifest.json','r') as f:\n",
    "manifest = json.load(f)\n",
    "# choose the last (largest) entry\n",
    "entry = manifest[-1]\n",
    "features_file = entry['file']\n",
    "print('Using features file:', features_file)\n",
    "\n",
    "\n",
    "subprocess.run([\n",
    "'python', 'src/experiments/run_group_ensemble.py',\n",
    "'--in', features_file,\n",
    "'--out', 'results/demo_group_ens',\n",
    "'--strategy', 'by_family',\n",
    "'--aggregation', 'weighted'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6405ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: run analysis and display the figure inline\n",
    "from src.analysis.run_analysis import plot_error_vs_features, best_model_per_bucket\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sweep_csv = 'results/demo_sweep/sweep_results_final.csv'\n",
    "df = pd.read_csv(sweep_csv)\n",
    "plot_error_vs_features(df, out_path='results/demo_fig_error_vs_features.png', metric_col='test_rmse')\n",
    "img = plt.imread('results/demo_fig_error_vs_features.png')\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Best model per bucket:')\n",
    "print(best_model_per_bucket(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8dc1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32869427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
